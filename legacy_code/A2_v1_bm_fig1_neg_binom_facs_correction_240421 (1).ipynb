{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emotional-toddler",
   "metadata": {},
   "source": [
    "# Model Details:\n",
    "\n",
    "In statistics, an additive model (AM) is a nonparametric regression method. It was suggested by Jerome H. Friedman and Werner Stuetzle (1981)[1] and is an essential part of the ACE algorithm. The AM uses a one-dimensional smoother to build a restricted class of nonparametric regression models. Because of this, it is less affected by the curse of dimensionality than e.g. a p-dimensional smoother. Furthermore, the AM is more flexible than a standard linear model, while being more interpretable than a general regression surface at the cost of approximation errors. Problems with AM include model selection, overfitting, and multicollinearity.\n",
    "\n",
    "#### Overall Regression model\n",
    "- The regression model is a two-way additive model with Age and celltype effects. The data are a full unreplicated design. Two-Factor ANOVA is multiple regression with two categorical explanatory\n",
    "variables (or factors).\n",
    "\n",
    "#### Per cell Regression model\n",
    "- The regression model is a quasibinimial regression with Age effects. The data are a full unreplicated design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-force",
   "metadata": {},
   "source": [
    "## <h1><center>Quasibinomial model</center></h1>\n",
    "$$ P(X=k)={n \\choose k}p(p+k\\phi)^{k-1}(1-p-k\\phi)^{n-k} $$\n",
    "$$Y = B_1 X_1 * B_2 X_2  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-dublin",
   "metadata": {},
   "source": [
    "# model resources:\n",
    "- https://hansjoerg.me/2019/05/10/regression-modeling-with-proportion-data-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-offense",
   "metadata": {},
   "source": [
    "write style:\n",
    "e.g. \"The phagocyte prevalence ratio was exp(\\beta_1) at baseline (95% CI...), this ratio decreased by exp(\\gamma_1) at day 14 (95% CI...) and by exp(\\gamma_2) at day 28 (95% CI). A global trend test for group was performed, the p-value was X.XX see figure X.\n",
    "Ideally plot the predicted effect over time along with 95% CIs, since the last sentence is too technical for non-statistical reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-choir",
   "metadata": {},
   "source": [
    "## <h1><center>FACS correction</center></h1>\n",
    "\n",
    "$$ CorrectedCounts = SortProportion_n* \\Bigg[\\frac{observed counts_{n,i}} {Sample group_n}\\Bigg] * Sample Total_t $$\n",
    "\n",
    "\n",
    "- SortProportion : The proportion this gate was observed at during sorting for sample (n). (count/total_events)\n",
    "- Sample Group : cell counts contributed by the gate of interest (g) - total number of cells in lane \n",
    "- SampleTotal : Sum of counts of all cells contributed by this gating strategy (t) (by both gates per donor)\n",
    "- Observed_counts : The counts belonging to each annotated cellstate of interest (i) per donor\n",
    "\n",
    "i=index over the nhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Issac Goh\n",
    "#Date: 010620\n",
    "#Modified: 010620\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#Tips\n",
    "\n",
    "# x is a dataframe with the following columns in this specific order:\n",
    "# x$variable # celltype\n",
    "# x$value # cell count\n",
    "# x$batch # condition_donor\n",
    "# x$timepoint # condition (e.g. adult, fetal)\"\n",
    "\n",
    "#If you are importing a metafata dataframe from another object, \n",
    "#use below to import and subset the data to columns of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-movement",
   "metadata": {},
   "source": [
    "#### Create a mapped FACs correction table module (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_facs_map = FALSE\n",
    "{\n",
    "var_time = \"age\"\n",
    "var_ID = \"orig.ident\"\n",
    "var_sort = \"sort.ids\"\n",
    "var_tissue = \"origin\"\n",
    "meta_dat_add  = \"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/metadata/fbm_updated_20200718.csv\" \n",
    "out_add_fname = \"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/facs_map.csv\"\n",
    "}\n",
    "\n",
    "#This module checks if all variables are available in the FACs map, else, a sort probability of 1 will be added to the sample.\n",
    "Check_facs_map = TRUE\n",
    "{\n",
    "facs_map_add = \"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/facs_sort_strategy/BM_Facs_gate_sort.csv\"\n",
    "meta_dat_add  = \"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/facs_sort_strategy/facs_map_v2.csv\"\n",
    "var_time = \"age\"\n",
    "var_ID = \"orig.ident\"\n",
    "var_sort = \"sort.ids\"\n",
    "var_tissue = \"origin\"\n",
    "}\n",
    "\n",
    "if (Create_facs_map == TRUE) {\n",
    "    #Extract unique age, facs and identity\n",
    "    meta = read.csv(meta_dat_add)\n",
    "    #age = as.character(meta$fetal.ids)\n",
    "    #age = gsub(\"SB19PCW\",\"fca_SB_19PCW\",age)\n",
    "    #age = sapply(strsplit(age,c(\"_\")), `[`, 3)\n",
    "    #age = gsub(\"[+].\",\"\",age)\n",
    "    #age = gsub(\"PCW\",\"\",age)\n",
    "    #meta$age <- age\n",
    "    out <- meta[c(var_ID,var_time,var_sort,var_tissue)]\n",
    "    out$FACs_prop <- \"\"\n",
    "    out_uni<-out[!duplicated(out),]\n",
    "    write.csv(out_uni,out_add_fname)\n",
    "    }\n",
    "\n",
    "if (Check_facs_map == TRUE) {\n",
    "    #Extract unique age, facs and identity\n",
    "    meta <- read.csv(meta_dat_add)\n",
    "    facs_map = read.csv(facs_map_add)\n",
    "    #Check that gating strategy makes sense in reference to metadata\n",
    "    ##To be written###\n",
    "    for (c in c(var_time,var_ID,var_sort,var_tissue)){\n",
    "    print(c)\n",
    "    #check\n",
    "    unique(meta[var_time])\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "facs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-quarter",
   "metadata": {},
   "source": [
    "# Data Preperation module [concat and correct multiple metadata tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Give adresses of metadata to concat\n",
    "#adrr<-(\"/Users/issac/Documents/Projects/Fetal Bone Marrow/BM_12052020_stats/meta_data_files/\")\n",
    "\n",
    "# - Concat data of interest\n",
    "#concat_adrr_book<-function(){\n",
    "#adress_book<- grep(list.files(path=adrr), pattern='concatenated_metadata.csv', inv=T, value=T)\n",
    "#if (\"met_concat\"%in%ls()){\n",
    "#  rm(met_concat)}\n",
    "#for (met_adr_temp in adress_book){\n",
    "#  met_temp <- read.csv(paste0(adrr,met_adr_temp))\n",
    "#  if (!\"met_concat\"%in%ls()){\n",
    "#    met_concat <- met_temp\n",
    "#  }else{\n",
    "#    met_concat <- plyr::rbind.fill(met_concat,met_temp)\n",
    "#  }\n",
    "#}\n",
    "#return(met_concat)\n",
    "#}\n",
    "#met_concat<-concat_adrr_book()\n",
    "#write.csv(met_concat,paste0(adrr,\"concatenated_metadata.csv\"))\n",
    "\n",
    "########################################\n",
    "#Annotation corrections:\n",
    "#meta<-met_concat\n",
    "#meta<-read.csv(meta_add,stringsAsFactors = F)\n",
    "\n",
    "#unique(grep(\"MONO\",meta$cell.labels[meta$origin==\"ys\"],value = T))\n",
    "#unique(grep(\"Neut\",meta$cell.labels,value = T))\n",
    "\n",
    "#cells_keep[!cells_keep%in%unique(meta$cell.labels[meta$origin==\"abm\"])]\n",
    "#Check annotations abm\n",
    "#unique(meta$cell.labels[meta$cell.labels%in%cells_list&meta$origin==\"abm\"])\n",
    "#unique(meta$cell.labels[meta$origin==\"abm\"])\n",
    "#unique(grep(\"B\",meta$cell.labels[meta$origin==\"abm\"],value = T))\n",
    "\n",
    "\n",
    "# - Read cell_list for each fig and define which is current figure\n",
    "fig_cell_list_key <- read.csv(\"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/figure_cells/cell.labels by figures.csv\",stringsAsFactors = F)\n",
    "fig_of_interest<-\"Figure.1\"\n",
    "cells_list<- as.character(unlist(fig_cell_list_key[fig_of_interest][!fig_cell_list_key[fig_of_interest]==\"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cell_list_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-sierra",
   "metadata": {},
   "source": [
    "# Variables input module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - choice of Negative binom of quasi binomial distribution ('quasi' or 'neg')\n",
    "dist <- \"quasi\" #'neg'#\"quasi\" \n",
    "\n",
    "# - metadata adress\n",
    "meta_add<-\"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/metadata/fbm_updated_20200718.csv\"\n",
    "#meta_add<-\"/nfs/team205/ig7/resources/scripts_dont_modify/neg_binom/resources/metadata/concatenated_metadata_old.csv\"\n",
    "\n",
    "# - FACS correction strategy\n",
    "FACS <- \"/nfs/team205/ig7/resources/scripts_dont_modify/neg_binom/resources/facs_sort_strategy/facs_map_v2.csv\"\n",
    "\n",
    "# - output directory to create\n",
    "output_dr<-\"/nfs/team205/ig7/resources/scripts_dont_modify/neg_binom/out/bm_overall_090421/\"\n",
    "\n",
    "# - input dependent cateogircal variable containing cell.label information\n",
    "dep_var<-\"broad_fig1_cell.labels\"\n",
    "\n",
    "# - input independent cateogircal variable containing the test conditions (e.g stage/pcw/sex)\n",
    "inde_var<-\"age\"#\"stage\"\n",
    "\n",
    "# - input categorical variable containing batch information (a column to compute dispersion coefficients)\n",
    "batch<-\"orig.ident\"\n",
    "\n",
    "# - input the sort_ids which correlate to the sorting stratey in the the metadata\n",
    "use_facs_map = TRUE\n",
    "var_sort = \"sort.ids\"\n",
    "#facs_map_add = \"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/resources/facs_sort_strategy/facs_map_v2.csv\"\n",
    "facs_map_add =\"/nfs/team205/ig7/resources/scripts_dont_modify/neg_binom/resources/facs_sort_strategy/BM_Facs_gate_sort_v2.csv\"\n",
    "correct_between = c(\"CD45-\",\"CD45+\")\n",
    "\n",
    "# - run name\n",
    "run_id <- \"fig1_bm_by_age_quasi\"\n",
    "\n",
    "# - if input data needs to be subset give list of indpendent categroricals to be kept (e.g stage/pcw/sex or \"all\")\n",
    "inde_keep<-c(\"all\")\n",
    "\n",
    "# - give list of cell labels in verbatim to metadata to subset the data by (note that the cell.labels of analougous populations must match across data)\n",
    "cells_keep<- cells_list #()\n",
    "meta = read.csv(meta_add,stringsAsFactors = F)\n",
    "#cells_keep <- unique(meta[,dep_var])\n",
    "\n",
    "#Only test overall: select if you only have one sample per timepoint on average\n",
    "overall = FALSE\n",
    "\n",
    "\n",
    "\n",
    "#Function to install/load libraries required\n",
    "libs<-c(\"base\",\"dplyr\",\"data.table\",\"plyr\",\"MASS\",\"stringr\",\"gdata\",\"reshape2\")#\"equatiomatic\"\n",
    "pkg_check <- function(pkg){\n",
    "  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n",
    "  if (length(new.pkg)) \n",
    "    install.packages(new.pkg,repos = \"https://cloud.r-project.org\", dependencies = TRUE)\n",
    "  sapply(pkg, require, character.only = TRUE)\n",
    "}\n",
    "pkg_check(libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta <- meta[(meta$origin==\"fbm\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta$sort.ids[is.nan(meta$sort.ids)]<-\"Total\"\n",
    "meta$sort.ids<-gsub(\"nan\",\"Total\",meta$sort.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(meta$'broad_fig1_cell.labels')[unique(meta$'broad_fig1_cell.labels') %in% cells_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-falls",
   "metadata": {},
   "source": [
    "# Make special assignments for CD45 +/-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "#celltype <- list(c(unique(meta[dep_var])))\n",
    "#mapper <-  list(c(\"CD45-\",\"CD45-\",\"CD45+\",\"CD45+\",\"CD45+\",\"CD45-\",\"CD45+\",\"CD45-\",\"CD45+\",\"CD45+\"))\n",
    "#require(reshape2)\n",
    "#mapper <- melt(data.frame(celltype,mapper))\n",
    "#colnames(mapper)<-c(dep_var,var_sort)\n",
    "#mapper[,(dep_var)] <- toupper(mapper[,(dep_var)])\n",
    "#meta[,(dep_var)] <- toupper(meta[,(dep_var)] )\n",
    "#meta[,(var_sort)][!meta[,(var_sort)]==\"Total\"]<-mapvalues(meta[,(dep_var)][!meta[,(var_sort)]==\"Total\"],mapper[,(dep_var)],mapper[,(var_sort)])\n",
    "\n",
    "#sort = \"CD45+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CD45+ gating strategy\n",
    "#meta1<-meta[(meta[,(var_sort)]%in%c(\"CD45+\")),]\n",
    "#meta2<-meta[(meta[,(var_sort)]%in%c(\"Total\")),]\n",
    "#meta2[,(\"trial_sort\")]<-mapvalues(meta2[,(dep_var)],mapper[,(dep_var)],mapper[,(var_sort)])\n",
    "#meta2 <- meta2[(meta2[,(\"trial_sort\")]%in%c(\"CD45+\")),]\n",
    "#meta2$trial_sort<-NULL\n",
    "#meta <- rbind(meta1,meta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-fabric",
   "metadata": {},
   "source": [
    "# Env setup and functions module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting Age variable for BM\n",
    "age = as.character(meta$fetal.ids)\n",
    "age = gsub(\"SB19PCW\",\"fca_SB_19PCW\",age)\n",
    "age = sapply(strsplit(age,c(\"_\")), `[`, 3)\n",
    "age = gsub(\"[+].\",\"\",age)\n",
    "age = gsub(\"PCW\",\"\",age)\n",
    "meta$age <- age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "#Function to install/load libraries required\n",
    "libs<-c(\"base\",\"dplyr\",\"data.table\",\"plyr\",\"MASS\",\"stringr\",\"gdata\",\"reshape2\")#\"equatiomatic\"\n",
    "pkg_check <- function(pkg){\n",
    "  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n",
    "  if (length(new.pkg)) \n",
    "    install.packages(new.pkg,repos = \"https://cloud.r-project.org\", dependencies = TRUE)\n",
    "  sapply(pkg, require, character.only = TRUE)\n",
    "}\n",
    "pkg_check(libs)\n",
    "\n",
    "#create and Set working directory\n",
    "if (!file.exists(output_dr)){\n",
    "dir.create(output_dr)\n",
    "}\n",
    "setwd(output_dr)\n",
    "\n",
    "#Read the metadata and subset to independent and dependent categoricals of interest\n",
    "if (!\"meta\"%in%ls()){\n",
    "meta<-read.csv(meta_add,stringsAsFactors = F)\n",
    "}\n",
    "\n",
    "if (use_facs_map == TRUE){\n",
    "    # facs correction module\n",
    "    facs_map = read.csv(facs_map_add)\n",
    "    meta<- meta[,c(batch,dep_var,inde_var,var_sort)]\n",
    "    cells_keep <- toupper(cells_keep)\n",
    "    meta[,dep_var]<-toupper(meta[,dep_var])\n",
    "    \n",
    "     if(inde_keep==\"all\"){\n",
    "      print(\"option to use all independent variables chosen, automatically assigning comparison for everything\")\n",
    "    }else{\n",
    "      print(paste0(\"option to subset of independent variables chosen, automatically assigning comparison for:\",inde_keep))\n",
    "      meta<-meta[(meta[,inde_var]%in%inde_keep),]\n",
    "    }\n",
    "    meta<-meta[(meta[,dep_var]%in%cells_keep),]\n",
    "\n",
    "    #Check if unique labels count is equal to cell_keep\n",
    "    if(!length(unique(meta[,dep_var])) == length(cells_keep)){\n",
    "      warning(\"length of cell_list and unique labels is not equal, check spelling\")\n",
    "    }\n",
    "    \n",
    "    #Assign a freq count value per cell\n",
    "    meta$freq = 1\n",
    "    #Aggregate the metadata in by grouping variable ()\n",
    "    meta[batch] <- as.vector(meta[batch])\n",
    "    meta[,batch][is.na(meta[,batch])] <- \"not_specified\"\n",
    "    x <- aggregate(meta[,c(\"freq\")], meta[,c(colnames(meta)[!colnames(meta)%in%\"freq\"])], FUN = sum)\n",
    "    #x[var_sort][x[var_sort]==\"nan\"] <-\"Total\"\n",
    "\n",
    "    #convert all labels to uppercase (minimises errors)\n",
    "    x <- as.data.frame(x%>%apply(2,toupper))\n",
    "    #relabel and reorder x\n",
    "    colnames(x)<- c(\"batch\",\"variable\",\"timepoint\",\"sort\",\"value\")\n",
    "    col_order <- c(\"value\",\"timepoint\",\"variable\",\"batch\",\"sort\")\n",
    "    x <- x[, col_order]\n",
    "\n",
    "    #Create a mappable field in both dfs\n",
    "    x$ident_sort <- paste0(x$batch,x$sort)\n",
    "    x$ident_sort <- toupper(x$ident_sort)\n",
    "    facs_map$ident_sort <- paste0(facs_map[,batch],facs_map[,var_sort])\n",
    "    facs_map$ident_sort <- toupper(facs_map$ident_sort)\n",
    "    x$value<-as.integer(x$value)\n",
    "\n",
    "    #get the grouped counts for sort ids within defined \"correct within\" args\n",
    "    x <- as.data.table(x)\n",
    "    x_temp <- x[x$sort%in%correct_between]\n",
    "    x_temp[, sample_total := sum(value), by = batch]\n",
    "    x_temp[, lane_count := sum(value), by = ident_sort]\n",
    "    x_unsorted <- x[!x$sort%in%correct_between]\n",
    "    x_unsorted[, sample_total := sum(value), by = batch]\n",
    "    x_unsorted[, lane_count := sum(value), by = ident_sort]\n",
    "    x<-rbind(x_temp, x_unsorted)\n",
    "\n",
    "    \n",
    "    #map the multipliers\n",
    "    x$sort_multiplier <- mapvalues(x$ident_sort,facs_map$ident_sort,as.numeric(facs_map$parent_Multiplier))\n",
    "\n",
    "    #Make the corrections\n",
    "    x$corrected_counts <- (as.numeric(x$sort_multiplier)*x$sample_total*(x$value/x$lane_count))\n",
    "    x$pre_correction_counts <- x$value\n",
    "    x$value <- x$corrected_counts\n",
    "    \n",
    "    #Convert data to proportional data if quasibinom option chosen\n",
    "    if(dist==\"quasi\"){\n",
    "        x_temp <- x[x$sort%in%correct_between]\n",
    "        x_temp<- x_temp %>% dplyr::group_by(batch) %>% dplyr::mutate(percent = corrected_counts/sample_total)\n",
    "        x_unsorted <- x[!x$sort%in%correct_between]\n",
    "        x_unsorted <- x_unsorted %>% dplyr::group_by(batch) %>% dplyr::mutate(percent = corrected_counts/sample_total)\n",
    "        x<-rbind(x_temp, x_unsorted)  \n",
    "    }\n",
    "    } #End of facs correction\n",
    "    else{ #if no facs correction\n",
    "    meta<- meta[,c(batch,dep_var,inde_var)]\n",
    "    cells_keep <- toupper(cells_keep)\n",
    "    meta[,dep_var]<-toupper(meta[,dep_var])\n",
    "\n",
    "    if(inde_keep==\"all\"){\n",
    "      print(\"option to use all independent variables chosen, automatically assigning comparison for everything\")\n",
    "    }else{\n",
    "      print(paste0(\"option to subset of independent variables chosen, automatically assigning comparison for:\",inde_keep))\n",
    "      meta<-meta[(meta[,inde_var]%in%inde_keep),]\n",
    "    }\n",
    "    meta<-meta[(meta[,dep_var]%in%cells_keep),]\n",
    "\n",
    "    #Check if unique labels count is equal to cell_keep\n",
    "    if(!length(unique(meta[,dep_var])) == length(cells_keep)){\n",
    "      warning(\"length of cell_list and unique labels is not equal, check spelling\")\n",
    "    }\n",
    "\n",
    "    #Assign a freq count value per cell\n",
    "    meta$freq = 1\n",
    "\n",
    "    #Aggregate the metadata in by grouping variable ()\n",
    "    meta[batch] <- as.vector(meta[batch])\n",
    "    meta[,batch][is.na(meta[,batch])] <- \"not_specified\"\n",
    "    x <- aggregate(meta[,c(\"freq\")], meta[,c(colnames(meta)[!colnames(meta)%in%\"freq\"])], FUN = sum)\n",
    "    #convert all labels to uppercase (minimises errors)\n",
    "    x <- as.data.frame(x%>%apply(2,toupper))\n",
    "    #relabel and reorder x\n",
    "    colnames(x)<- c(\"batch\",\"variable\",\"timepoint\",\"value\")\n",
    "    col_order <- c(\"value\",\"timepoint\",\"variable\",\"batch\")\n",
    "    x <- x[, col_order]\n",
    "    x$value<-as.integer(x$value)\n",
    "    \n",
    "    #Convert data to proportional data if quasibinom option chosen\n",
    "    if(dist==\"quasi\"){\n",
    "      x <- x %>% dplyr::group_by(batch) %>% dplyr::mutate(percent = value/sum(value))\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Define all your conditions that group your replicates as the \"batch variable\" (e.g donors), this goes into df of conditional \"variates\"\n",
    "len = length(unique(x$batch))\n",
    "condition = as.data.frame(1: len)\n",
    "colnames(condition)<-\"len\"\n",
    "condition$len <-gsub(\"^\",\"cond_\",condition$len)\n",
    "condition$cond <-unique(x$batch)\n",
    "\n",
    "# Define the variates in \"condition$cond\" across dataset\n",
    "conditions<-as.character(unique(x$timepoint))\n",
    "\n",
    "# Define as many empty variables as many conditions you want to test:\n",
    "n<-length(conditions)\n",
    "test_vecs<-as.data.frame(gtools::combinations(n,2,conditions))\n",
    "\n",
    "#Create a unpopulated df\n",
    "score_results<- data.frame(row.names = paste0(test_vecs$V1,\"_vs_\",test_vecs$V2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-handbook",
   "metadata": {},
   "source": [
    "# Compute module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall\n",
    "#nb = glm(formula = percent ~ timepoint+celltype, data = x1, family=quasibinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the p-values for increasing labeled fraction (using negative binomial regression)\n",
    "  if(\"score_results_concat\"%in%ls()){\n",
    "    remove(score_results_concat)\n",
    "  }\n",
    "spearman_tot <-vector()\n",
    "  pv_tot <-vector()\n",
    "  for(i in 1:length(unique(x$variable))){\n",
    "    #pv_temp<-vector()\n",
    "    pv_temp<-rep(\"NA\",NROW(score_results))\n",
    "    temp_test_list<-vector()\n",
    "    x$variable <- factor(x$variable)\n",
    "    cell = levels(x$variable)[i]\n",
    "    totals = aggregate(x$value, by = list(x$batch), FUN = sum)\n",
    "    colnames(totals) <- c(\"batch\", \"total\")   \n",
    "      \n",
    "    #cell = \"ERYTHROID\"\n",
    "      \n",
    "    d = data.frame(subset(x, variable == cell))\n",
    "    d <- merge(d, totals, by = \"batch\")\n",
    "    #QC block\n",
    "    if(any(d$total == 0)) {\n",
    "      warning(\"Removing sample that didn't detect this celltype\")\n",
    "      d = subset(d, total > 0)\n",
    "    }\n",
    "\n",
    "    #Aggregate D to only columns required\n",
    "    if(\"ident_sort\" %in% colnames(d))\n",
    "     {\n",
    "       d$ident_sort <- NULL\n",
    "        #d$sort <- NULL\n",
    "        d$sort_multiplier <- NULL\n",
    "     }\n",
    "    d <- d %>%group_by(variable,batch,timepoint,sort) %>%summarise_each(funs(sum))\n",
    "    d$sort = NULL \n",
    "    d <- d %>%group_by(variable,batch,timepoint) %>% summarise_each(funs(mean))\n",
    "      \n",
    "    #Order factor levels in timepoint variable\n",
    "    levels(d$timepoint)<-unique(sort(d$timepoint))\n",
    "    d <- d[order(d$timepoint),]\n",
    "      \n",
    "    if(length(unique(d$timepoint))<=1){\n",
    "      warning(\"One or fewer unique independent variables detected in loop, proceeding with next loop\")\n",
    "    }else{\n",
    "      for (ref in 1:NROW(test_vecs)){\n",
    "        temp_vec<-test_vecs[ref,]\n",
    "        reference <- as.character(unlist(temp_vec[1]))\n",
    "        test <-as.character(unlist(temp_vec[2]))\n",
    "        test_name<-paste0(reference,\"_v_\",test)\n",
    "        temp_test_list[ref] = test_name\n",
    "        #test block\n",
    "        \n",
    "        if (!overall==TRUE){\n",
    "        if(reference%in%d$timepoint&&test%in%d$timepoint){\n",
    "          x1 = d[d$timepoint %in% c(reference, test), ]\n",
    "          if(dist==\"quasi\"){\n",
    "            nb = glm(formula = percent ~ timepoint, data = x1, family=quasibinomial)#Add sort interaction term\n",
    "            #Error checking\n",
    "            t <- try(anova(nb, test = \"F\")$`Pr(>F)`[2])\n",
    "            if(\"try-error\" %in% class(t)){pv_temp[ref]<-\"NA\"}else{\n",
    "            pv_temp[ref] = anova(nb, test = \"F\")$`Pr(>F)`[2]\n",
    "            }\n",
    "            score_results[,cell] <- pv_temp\n",
    "          }else{\n",
    "            d$value <- as.integer(d$value)\n",
    "            nb = MASS::glm.nb(formula = value ~ timepoint + offset(log(as.numeric(x1$total))), data = x1, maxit = 1000)#, control=glm.control(trace = 3))\n",
    "              tryCatch(anova(nb, test = \"LRT\")$`Pr(>Chi)`[2],error=function(e){pv_temp[ref]<<-\"NA\"})\n",
    "              pv_temp[ref] = anova(nb, test = \"LRT\")$`Pr(>Chi)`[2]\n",
    "              score_results[,cell] <- pv_temp\n",
    "          }\n",
    "        }\n",
    "        }\n",
    "      }\n",
    "      #Compute overall score\n",
    "      if(dist==\"quasi\"){\n",
    "        #d <- aggregate(d[,c(\"percent\")], d[,c(\"batch\",'timepoint')], FUN = sum)\n",
    "        #d$percent <- d$x\n",
    "        nb_tot = glm(formula = percent ~ timepoint, data = d, family=quasibinomial) #Add sort interaction term\n",
    "        #Error checking\n",
    "        #t <- try(anova(nb_tot, test = \"F\")$`Pr(>F)`[2])\n",
    "        t <- try(anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2])  \n",
    "        if(\"try-error\" %in% class(t)){pav_tot_val<-\"NA\"}else{\n",
    "        pav_tot_val<-anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2]\n",
    "        }\n",
    "      if(is.na(pav_tot_val)==FALSE){\n",
    "        pv_tot[i] = pav_tot_val\n",
    "      }else{\n",
    "        pv_tot[i] <- \"NA\"\n",
    "      }\n",
    "      }else{\n",
    "        d$value <- as.integer(d$value)\n",
    "        nb_tot = MASS::glm.nb(formula = value ~ timepoint + offset(log(as.numeric(d$total))), data = d, maxit = 1000)#, control=glm.control(trace = 3))\n",
    "        pav_tot_val <- anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[4]\n",
    "      if(is.na(pav_tot_val)==FALSE){\n",
    "        pv_tot[i] = pav_tot_val\n",
    "      }else{\n",
    "        pv_tot[i] <- \"NA\"\n",
    "      }\n",
    "      }\n",
    "    #test sperman's\n",
    "    d$timepoint <- gsub(\"STAGE \",\"\",d$timepoint)\n",
    "    spearman <- cor.test(d$percent,as.numeric(d$timepoint),method = \"spearman\")\n",
    "    pval_spearman <- spearman$p.value\n",
    "    spearman_tot[i] <- pval_spearman\n",
    "      \n",
    "    }\n",
    "    #if(!\"score_results_concat\"%in%ls()){\n",
    "    #  score_results_concat<-score_results\n",
    "    #}else{\n",
    "    #  score_results_concat<-cbind(score_results_concat,score_results)\n",
    "    #}\n",
    "  }\n",
    "  score_results_final<-rbind(score_results,spearman_tot,pv_tot)\n",
    "  base::row.names(score_results_final[NROW(score_results_final),])<-\"overall\"\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "####results module####\n",
    "rownames(score_results_final)[rownames(score_results_final)%in%rownames(tail(score_results_final,2))] <- c(\"Spearmans_test\",\"overall_per_cell\")\n",
    "score_results_final<-score_results_final[,order(colnames(score_results_final))]\n",
    "\n",
    "#add sig codes\n",
    "sig_codes<- tail(score_results_final,1)\n",
    "for (z in colnames(sig_codes)){\n",
    "     if(sig_codes[z][,1]<0.00099){\n",
    "       sig_codes[z]<-\"***\" }\n",
    "    if(sig_codes[z][,1]<0.0099){\n",
    "       sig_codes[z]<-\"**\" }\n",
    "    if(sig_codes[z][,1]<0.05){\n",
    "       sig_codes[z]<-\"*\" }\n",
    "    else{sig_codes[z] <- 'ns'}\n",
    "}\n",
    "rownames(sig_codes)<-\"sig_codes\"\n",
    "score_results_final<-rbind(score_results_final,sig_codes)\n",
    "\n",
    "#add overarching pval for  two-way additive model with celltype and time\n",
    "tot <- aggregate(x[,c(\"percent\")], x[,c(\"batch\",'timepoint','variable')], FUN = sum)\n",
    "nb_overall = glm(formula = percent ~  variable * timepoint, data = tot, family=quasibinomial)\n",
    "pav_overall_val<-anova(nb_overall, test = \"F\")\n",
    "pav_overall_val<-tail(pav_overall_val,1)[,\"Pr(>F)\"]\n",
    "score_results_final[nrow(score_results_final)+1,][1]<-pav_overall_val\n",
    "rownames(score_results_final)[rownames(score_results_final)==rownames(tail(score_results_final,1))] <-\"overarching_all_cells_all_timepoints\"\n",
    "\n",
    "date<-gsub( \" .*$\", \"\", Sys.time())\n",
    "write.csv(score_results_final,paste0(output_dr,\"/\",run_id,\"_\",date,\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove cells expt for sort of interest\n",
    "#meta1<-x[(x$sort==sort),]\n",
    "#meta2<-x[(x$sort==\"TOTAL\"),]\n",
    "#meta2[,(\"trial_sort\")]<-mapvalues(meta2$variable,mapper[,(dep_var)],mapper[,(var_sort)])\n",
    "##meta2 <- meta2[(meta2$trial_sort==sort),]\n",
    "#meta2$trial_sort<-NULL\n",
    "#x <- rbind(meta1,meta2)\n",
    "#x$corrected_counts <- (as.numeric(x$sort_multiplier)*x$sample_total*(x$value/x$sample_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if(\"ident_sort\" %in% colnames(x))\n",
    "     {\n",
    "    out<-copy(x)\n",
    "       out$ident_sort <- NULL\n",
    "        out$sort <- NULL\n",
    "        out$sort_multiplier <- NULL\n",
    "     }\n",
    "out<-out %>%group_by(timepoint,variable,batch) %>% summarise_each(funs(sum))\n",
    "#out\n",
    "\n",
    "    if(\"ident_sort\" %in% colnames(x))\n",
    "     {\n",
    "    out<-copy(x)\n",
    "       out$ident_sort <- NULL\n",
    "        out$sort <- NULL\n",
    "        out$sort_multiplier <- NULL\n",
    "        out$batch <- NULL\n",
    "     }\n",
    "out<-out %>%group_by(timepoint,variable) %>% summarise_each(funs(sum))\n",
    "out<-copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "NROW(meta[(meta$orig.ident =='SB19PCW'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.csv(out,paste0(output_dr,\"fig1_corrected_proportions_CD45_pos.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.csv(x,paste0(output_dr,\"fig1_corrected_proportions.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write.csv(x,paste0(output_dr,\"fig1_corrected_proportions.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(d,aes(y=percent ,x=timepoint,color=factor(batch)))+geom_point()+stat_smooth(method=\"lm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    if(\"ident_sort\" %in% colnames(d))\n",
    "#     {\n",
    "#    out_d<-copy(d)\n",
    "#       out_d$ident_sort <- NULL\n",
    "#        out_d$sort <- NULL\n",
    "#        out_d$sort_multiplier <- NULL\n",
    "#     }\n",
    "#out_d<-out_d %>%group_by(timepoint,variable,batch) %>% summarise_each(funs(sum))\n",
    "#out_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(out_d,aes(y=percent ,x=timepoint,color=factor(batch)))+geom_point()+stat_smooth(method=\"lm\",se=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-indie",
   "metadata": {},
   "source": [
    "# Trend testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide if prop goes up or down (use non-parametric trend test)\n",
    "\n",
    "direction = NULL\n",
    "cell_list = NULL\n",
    "rho = NULL\n",
    "r = NULL\n",
    "for(i in 1:length(unique(x$variable))) {\n",
    "  cell = levels(x$variable)[i]\n",
    "  d = data.frame(subset(x, variable == cell))\n",
    "  totals = aggregate(d$percent, by = list(d$timepoint), FUN = sum)\n",
    "  colnames(totals) <- c(\"timepoint\", \"total\")\n",
    "  d <- merge(d, totals, by = \"timepoint\")\n",
    "  #d <- d[(!d$timepoint==\"STAGE 4\"),]\n",
    "    \n",
    "    if(\"ident_sort\" %in% colnames(d))\n",
    "     {\n",
    "       d$ident_sort <- NULL\n",
    "        #d$sort <- NULL\n",
    "        d$sort_multiplier <- NULL\n",
    "     }\n",
    "    d <- d %>%group_by(variable,batch,timepoint,sort) %>%summarise_each(funs(sum))\n",
    "    d$sort = NULL \n",
    "    d <- d %>%group_by(variable,batch,timepoint) %>% summarise_each(funs(mean))\n",
    "  \n",
    "  #Create order for factors\n",
    "  order(unique(d$timepoint))\n",
    "  d$factor_levels <- ordered(d$timepoint, levels = c(\"STAGE 1\", \"STAGE 2\", \"STAGE 3\", \"STAGE 4\"))\n",
    "  #d$factor_levels <- ordered(d$timepoint, levels = c(\"DOWNS\", \"FBM\"))\n",
    "  d1<-d[!duplicated(d$timepoint),]\n",
    "  d1$time_factor <- order(d1$factor_levels)\n",
    "  \n",
    "  if(length(unique(d$timepoint))>=2){\n",
    "    print(\"parameters met to use Bartels trend test statistic\")\n",
    "    #d1$time_factor<-order(d1$timepoint)\n",
    "    ts_d<-as.ts(d1)\n",
    "    #sig<-bartels.test(ts_d)\n",
    "    sig <- cor.test(d1$percent,d1$time_factor,method = \"spearman\")\n",
    "    t <- try(cor.test(d1$percent,d1$time_factor,method = \"pearson\"))\n",
    "    if(\"try-error\" %in% class(t)){ \n",
    "        sig2 <-\"NA\"\n",
    "        r <- append(r, \"NA\")}else{\n",
    "    sig2 <- cor.test(d1$total,d1$time_factor,method = \"pearson\")\n",
    "    r <- append(r, sig2$estimate)\n",
    "    }\n",
    "      \n",
    "    \n",
    "    cell_list <- append(cell_list,cell)\n",
    "    rho<- append(rho,sig$estimate)\n",
    "    if(as.numeric(sig$estimate) == '1' ){\n",
    "      #direction <- append(direction,\"No_direction\")\n",
    "      reference <-as.character(d1$timepoint[d1$time_factor== min(d1$time_factor)]) # !\n",
    "      test <- as.character(d1$timepoint[d1$time_factor== max(d1$time_factor)]) # !\n",
    "      x1 = d[d$time %in% c(reference, test), ]\n",
    "      x_sums_test <- sum(x1$value[x1$timepoint==test])\n",
    "      x_sums_ref<- sum(x1$value[x1$timepoint==reference])\n",
    "      if(x_sums_test > x_sums_ref){\n",
    "        direction <- append(direction,\"up\")\n",
    "      }else{\n",
    "        direction<-append(direction,\"down\")\n",
    "      }\n",
    "    }else if(sig$estimate > '0' ){\n",
    "      direction<-append(direction,\"up\")\n",
    "    }else{\n",
    "      direction<-append(direction,\"down\")\n",
    "    }\n",
    "    \n",
    "  }else{\n",
    "    #If no statistic can be applied, use simple arithmic and compare largest to smallest factor\n",
    "    reference <-as.character(d1$timepoint[d1$time_factor== min(d1$time_factor)]) # !\n",
    "    test <- as.character(d1$timepoint[d1$time_factor== max(d1$time_factor)]) # !\n",
    "    x1 = d[d$time %in% c(reference, test), ]\n",
    "    x_sums_test <- sum(x1$value[x1$timepoint==test])\n",
    "    x_sums_ref<- sum(x1$value[x1$timepoint==reference])\n",
    "    \n",
    "    cell_list <- append(cell_list,cell)\n",
    "    rho<- append(rho,\"NA\")\n",
    "    r<- append(r,\"NA\")\n",
    "    if(x_sums_test > x_sums_ref){\n",
    "      direction <- append(direction,\"up\")\n",
    "    }else{\n",
    "      direction<-append(direction,\"down\")\n",
    "    }\n",
    "  }\n",
    "}\n",
    "polarity<-data.frame(cell_list,direction,rho,r)\n",
    "write.csv(polarity,\"/nfs/team205/ig7/work_backups/backup_210306/scripts_dont_modify/neg_binom/out/reviewers_overall_bm_polarity.csv\")\n",
    "#pv$polarity_of_change <- direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-arbitration",
   "metadata": {},
   "source": [
    "# Append polarity scores to score sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity <- as.data.frame((t(polarity)))\n",
    "polarity <- as.data.frame(polarity)\n",
    "names(polarity) <- as.character(unlist(polarity[1,]))\n",
    "polarity = polarity[-1,]\n",
    "polarity_scores <- rbind(score_results_final,(polarity))\n",
    "\n",
    "date<-gsub( \" .*$\", \"\", Sys.time())\n",
    "write.csv(polarity_scores,paste0(output_dr,\"/\",run_id,\"_polarity_scores_\",date,\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"ggpubr\")\n",
    "\n",
    "ggqqplot(d$percent, ylab = \"prop_spread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Compute overall score\n",
    "      if(dist==\"quasi\"){\n",
    "        #d <- aggregate(d[,c(\"percent\")], d[,c(\"batch\",'timepoint')], FUN = sum)\n",
    "        #d$percent <- d$x\n",
    "        nb_tot = glm(formula = percent ~ timepoint, data = d, family=quasibinomial)\n",
    "        #Error checking\n",
    "        #t <- try(anova(nb_tot, test = \"F\")$`Pr(>F)`[2])\n",
    "        t <- try(anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2])  \n",
    "        if(\"try-error\" %in% class(t)){pav_tot_val<-\"NA\"}else{\n",
    "        pav_tot_val<-anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2]\n",
    "        }\n",
    "      if(is.na(pav_tot_val)==FALSE){\n",
    "        pv_tot[i] = pav_tot_val\n",
    "      }else{\n",
    "        pv_tot[i] <- \"NA\"\n",
    "      }\n",
    "      }else{\n",
    "        nb_tot = MASS::glm.nb(formula = value ~ timepoint + offset(log(as.numeric(d$total))), data = d, maxit = 1000)#, control=glm.control(trace = 3))\n",
    "        pav_tot_val <- anova(nb_tot, test = \"LRT\")$`Pr(>Chi)`[2]\n",
    "      if(is.na(pav_tot_val)==FALSE){\n",
    "        pv_tot[i] = pav_tot_val\n",
    "      }else{\n",
    "        pv_tot[i] <- \"NA\"\n",
    "      }\n",
    "      }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
